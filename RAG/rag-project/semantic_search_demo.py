#!/usr/bin/env python3
"""
Semantic Search Demo using Local Embeddings
Uses sentence-transformers for semantic similarity
"""

from sentence_transformers import SentenceTransformer
import numpy as np
from utils import read_techcorp_docs

# å¯åŠ¨æç¤º / Startup banner
print("ğŸ§  Semantic Search Demo (Local Embeddings)")
print("=" * 50)

# è¯»å–æ–‡æ¡£ï¼ˆä¸æ‰“å°è¯¦æƒ…ï¼‰/ Load documents (without verbose output)
docs, doc_paths = read_techcorp_docs()

# åŠ è½½æœ¬åœ°å‘é‡æ¨¡å‹ / Load local embedding model
model = SentenceTransformer('all-MiniLM-L6-v2')

# ç”Ÿæˆæ–‡æ¡£å‘é‡ / Generate embeddings for all documents
doc_embeddings = model.encode(docs)

# æµ‹è¯•æŸ¥è¯¢ï¼ˆå…³é”®è¯å¤±è´¥åœºæ™¯ï¼‰/ Test query that failed with keyword search
query = "distributed workforce policies"
print(f"ğŸ” Searching for: '{query}'")

# ç”ŸæˆæŸ¥è¯¢å‘é‡ / Generate embedding for query
query_embedding = model.encode([query])

# è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ / Calculate cosine similarities
similarities = np.dot(query_embedding, doc_embeddings.T).flatten()

# å– Top ç»“æœ / Get top results
top_indices = similarities.argsort()[-3:][::-1]

print("Results:")
for i, idx in enumerate(top_indices, 1):
    doc_name = doc_paths[idx].split('/')[-1]
    print(f"  {i}. Score: {similarities[idx]:.4f} - {doc_name}")

# åˆ¤æ–­æ˜¯å¦ç›¸å…³ / Check if we found relevant documents
if similarities[top_indices[0]] > 0.3:
    print("  âœ… Found relevant documents!")
else:
    print("  âŒ No relevant documents found!")

# ç»“è®ºè¯´æ˜ / Conclusion note
print("\nğŸ’¡ Semantic search success because:")
print("- Understands 'distributed workforce policies' â‰ˆ 'remote work policy'")
print("- Embeddings capture meaning, not just keywords!")

# å®Œæˆæç¤º / Completion banner
print("\nâœ… Semantic search demo completed!")
