#!/usr/bin/env python3
# 1) è¯¥è„šæœ¬å¯¹æ¯” grepã€TF-IDF ä¸ BM25 ä¸‰ç§æ£€ç´¢æ–¹æ³•; This script compares grep, TF-IDF, and BM25 retrieval.
# 2) å®ƒå®ç°äº†ä¸‰ç§è¯„åˆ†æµç¨‹å¹¶è¾“å‡ºå„è‡ªæ’å; It implements three scoring pipelines and prints rankings.
# 3) ä½¿ç”¨çš„ AI æŠ€æœ¯åŒ…æ‹¬ TF-IDF ä¸ BM25 ç­‰ç»å…¸ä¿¡æ¯æ£€ç´¢ç®—æ³•; AI techniques include TF-IDF and BM25 classical IR.
# 4) åœ¨æ•´ä¸ªå­¦ä¹ è„šæœ¬ä¸­ï¼Œå®ƒæ˜¯æ–¹æ³•å¯¹æ¯”ä¸è¯„ä¼°çš„ä¸­é—´ç¯èŠ‚; In the learning sequence, it is the evaluation midpoint.
# 5) å®ƒä¸è¯­ä¹‰ä¸å‘é‡æ£€ç´¢è„šæœ¬å½¢æˆæ¨ªå‘å¯¹æ¯”ï¼Œæ˜ç¡®å‡çº§æ–¹å‘; It provides a lateral comparison against semantic and vector search.
"""
Compare Search Methods
Demonstrates the differences between grep, TF-IDF, and BM25
"""

import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from rank_bm25 import BM25Okapi
from utils import get_doc_info

# ç®€å•å­—ç¬¦ä¸²åŒ¹é… / Simple grep-like search
def grep_search(query, documents):
    """Simple grep-like search - exact keyword matching"""
    results = []
    query_lower = query.lower()
    
    for i, doc in enumerate(documents):
        if query_lower in doc.lower():
            count = doc.lower().count(query_lower)
            results.append((i, count))
    
    results.sort(key=lambda x: x[1], reverse=True)
    return results

# TF-IDF æ£€ç´¢ / TF-IDF search
def tfidf_search(query, documents):
    """TF-IDF search using sklearn"""
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(documents)
    query_vector = vectorizer.transform([query])
    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()
    
    results = [(i, similarities[i]) for i in range(len(documents))]
    results.sort(key=lambda x: x[1], reverse=True)
    return results

# BM25 æ£€ç´¢ / BM25 search
def bm25_search(query, documents):
    """BM25 search using rank_bm25"""
    tokenized_docs = [re.sub(r'[^a-zA-Z\s]', '', doc.lower()).split() for doc in documents]
    bm25 = BM25Okapi(tokenized_docs)
    tokenized_query = re.sub(r'[^a-zA-Z\s]', '', query.lower()).split()
    scores = bm25.get_scores(tokenized_query)
    
    results = [(i, scores[i]) for i in range(len(documents))]
    results.sort(key=lambda x: x[1], reverse=True)
    return results

# ä¸»æµç¨‹ / Main entry
def main():
    """Main function to compare search methods"""
    print("ğŸ” Search Methods Comparison")
    print("=" * 60)
    
    # è¯»å–æ–‡æ¡£ / Load documents from techcorp-docs
    docs, doc_paths = get_doc_info()
    print()
    
    # æµ‹è¯•æŸ¥è¯¢ / Test query
    query = "remote work policy"
    print(f"ğŸ” Testing query: '{query}'")
    print("=" * 60)
    
    # Grep æ£€ç´¢ / Grep search
    print("\n1ï¸âƒ£ GREP SEARCH (Exact keyword matching):")
    grep_results = grep_search(query, docs)
    for rank, (doc_idx, count) in enumerate(grep_results[:3], 1):
        print(f"  {rank}. Doc {doc_idx+1}: {count} matches - {docs[doc_idx][:80]}...")
    
    # TF-IDF æ£€ç´¢ / TF-IDF search
    print("\n2ï¸âƒ£ TF-IDF SEARCH (Term frequency-inverse document frequency):")
    tfidf_results = tfidf_search(query, docs)
    for rank, (doc_idx, score) in enumerate(tfidf_results[:3], 1):
        print(f"  {rank}. Doc {doc_idx+1}: Score {score:.4f} - {docs[doc_idx][:80]}...")
    
    # BM25 æ£€ç´¢ / BM25 search
    print("\n3ï¸âƒ£ BM25 SEARCH (Okapi BM25 with document length normalization):")
    bm25_results = bm25_search(query, docs)
    for rank, (doc_idx, score) in enumerate(bm25_results[:3], 1):
        print(f"  {rank}. Doc {doc_idx+1}: Score {score:.4f} - {docs[doc_idx][:80]}...")
    
    # è¾“å‡ºæ€»ç»“ / Print summary
    print(f"\nâœ… Search methods comparison completed!")
    print("\nğŸ’¡ Key Insights:")
    print("- Grep: Simple exact matching, good for specific terms")
    print("- TF-IDF: Balances term frequency with document rarity")
    print("- BM25: Advanced ranking with document length normalization")

# å…¥å£ä¿æŠ¤ / Entry point guard
if __name__ == "__main__":
    main()