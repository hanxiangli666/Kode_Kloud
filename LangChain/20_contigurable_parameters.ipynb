{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3dd6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1. 使用默认模型 (GPT-3.5-turbo) ===\n",
      "[模型]: gpt-3.5-turbo-0125\n",
      "[输出]:\n",
      "Particles dance in\n",
      "waves of probability\n",
      "Reality shifts\n",
      "\n",
      "=== 2. 运行时动态切换模型 (GPT-4o) ===\n",
      "[模型]: gpt-4o-2024-08-06\n",
      "[输出]:\n",
      "Particles whisper,  \n",
      "Entangled in dance of light—  \n",
      "Worlds in a blink merge.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 【硬性要求】加载环境变量，确保能读取到 OPENAI_API_KEY\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "# ==========================================\n",
    "# 1. 初始化带有“可配置字段”的模型\n",
    "# ==========================================\n",
    "# 【科研级保姆注释】\n",
    "# 旧版本：ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "# 现代写法：推荐直接使用 `model` 参数。\n",
    "# 我们通过 .configurable_fields() 为其绑定一个配置钩子。\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7).configurable_fields(\n",
    "    # 将内部的 \"model\" 参数暴露为可配置的字段\n",
    "    model_name=ConfigurableField(\n",
    "        id=\"llm_model_id\", # 这个 ID 是你在运行时调用的钥匙\n",
    "        name=\"LLM Model Name\",\n",
    "        description=\"The GPT model version to use for this specific task\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 2. 构建基础提示词与链\n",
    "# ==========================================\n",
    "prompt = PromptTemplate.from_template(\"Write a Haiku (俳句) on {subject}\")\n",
    "chain = prompt | model\n",
    "\n",
    "# ==========================================\n",
    "# 3. 动态调用演示\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    subject_topic = \"quantum physics\" # 用量子物理写首诗\n",
    "    \n",
    "    print(\"=== 1. 使用默认模型 (GPT-3.5-turbo) ===\")\n",
    "    # 直接 invoke，触发默认设置\n",
    "    default_response = chain.invoke({\"subject\": subject_topic})\n",
    "    print(f\"[模型]: {default_response.response_metadata.get('model_name')}\")\n",
    "    print(f\"[输出]:\\n{default_response.content}\\n\")\n",
    "    \n",
    "    print(\"=== 2. 运行时动态切换模型 (GPT-4o) ===\")\n",
    "    # 【核心魔法】：使用 .with_config() 在运行时注入新参数\n",
    "    # 这里的键 \"llm_model_id\" 必须与上面 ConfigurableField 定义的 id 完全一致\n",
    "    advanced_response = chain.with_config(\n",
    "        configurable={\"llm_model_id\": \"gpt-4o\"}\n",
    "    ).invoke({\"subject\": subject_topic})\n",
    "    \n",
    "    print(f\"[模型]: {advanced_response.response_metadata.get('model_name')}\")\n",
    "    print(f\"[输出]:\\n{advanced_response.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
