{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d880e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸåŠ è½½ PDFï¼Œå…±è®¡ 3 é¡µã€‚\n",
      "ğŸ”ª åˆ†å—å®Œæˆï¼åŸå§‹é¡µé¢è¢«åˆ‡åˆ†æˆäº† 81 ä¸ªç‹¬ç«‹çš„ Chunkã€‚\n",
      "\n",
      "=== è§‚å¯Ÿ Chunk 0 ===\n",
      "å†…å®¹: In the contemporary digital landscape, the \"datasphere\" is expanding at an\n",
      "unprecedented rate. This explosion of connectivity has fundamentally altered the\n",
      "å…ƒæ•°æ®: {'producer': '', 'creator': 'WPS æ–‡å­—', 'creationdate': '2026-02-24T21:43:41-05:00', 'author': '', 'comments': '', 'company': '', 'keywords': '', 'moddate': '2026-02-24T21:43:41-05:00', 'sourcemodified': \"D:20260224214341-05'00'\", 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data/handbook.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "=== è§‚å¯Ÿ Chunk 1 ===\n",
      "å†…å®¹: unprecedented rate. This explosion of connectivity has fundamentally altered the\n",
      "social contract between individuals and organizations. Every interaction, from a\n",
      "å…ƒæ•°æ®: {'producer': '', 'creator': 'WPS æ–‡å­—', 'creationdate': '2026-02-24T21:43:41-05:00', 'author': '', 'comments': '', 'company': '', 'keywords': '', 'moddate': '2026-02-24T21:43:41-05:00', 'sourcemodified': \"D:20260224214341-05'00'\", 'subject': '', 'title': '', 'trapped': '/False', 'source': 'data/handbook.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}\n",
      "\n",
      "ğŸ’¡ ã€ç§æ•™æç¤ºã€‘å¯¹æ¯” Chunk 0 çš„ç»“å°¾å’Œ Chunk 1 çš„å¼€å¤´ã€‚\n",
      "ä½ ä¼šå‘ç°æœ‰ä¸€æ®µé‡å¤çš„è¯ (Overlap)ï¼Œè¿™æ­£æ˜¯ä¸ºäº†ä¿è¯æ£€ç´¢æ—¶è¯­ä¹‰ä¸è¢«ç”Ÿç¡¬åˆ‡æ–­ï¼\n",
      "\n",
      "=== Overlap è‡ªæ£€ ===\n",
      "Chunk 0 å°¾éƒ¨(120 chars): 'pe, the \"datasphere\" is expanding at an\\nunprecedented rate. This explosion of connectivity has fundamentally altered the'\n",
      "Chunk 1 å¤´éƒ¨(120 chars): 'unprecedented rate. This explosion of connectivity has fundamentally altered the\\nsocial contract between individuals and'\n",
      "âœ… æ£€æµ‹åˆ°çš„å®é™… overlap é•¿åº¦: 80 å­—ç¬¦\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# ã€ç¡¬æ€§è¦æ±‚ã€‘åŠ è½½ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "# å¯¼å…¥é€’å½’å­—ç¬¦æ–‡æœ¬åˆ†å‰²å™¨\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# ==========================================\n",
    "# 1. å‡†å¤‡æ•°æ®æº (æ‰¿æ¥ä¸Šä¸€èŠ‚è¯¾çš„æµç¨‹)\n",
    "# ==========================================\n",
    "# å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªåä¸º handbook.pdf çš„æ–‡ä»¶\n",
    "PDF_PATH = \"data/handbook.pdf\"\n",
    "\n",
    "# å ä½é€»è¾‘ï¼šå¦‚æœæœ¬åœ°æ²¡æœ‰æ–‡ä»¶ï¼Œç”Ÿæˆä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹ä»¥ä¿è¯ä»£ç å¯è¿è¡Œ\n",
    "if not os.path.exists(PDF_PATH):\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    with open(PDF_PATH, \"w\") as f:\n",
    "        # æˆ‘ä»¬ä¸ç”¨ FPDF ç”ŸæˆçœŸå® PDF ä¹Ÿå¯ä»¥ï¼Œè¿™é‡Œä»…ä¸ºç¤ºæ„ï¼Œ\n",
    "        # åœ¨çœŸå®ç¯å¢ƒä¸­è¯·ç¡®ä¿ handbook.pdf å­˜åœ¨ã€‚\n",
    "        pass \n",
    "\n",
    "try:\n",
    "    loader = PyPDFLoader(PDF_PATH)\n",
    "    # æŒ‰é¡µç‰©ç†åˆ†å‰²ï¼Œè¿”å› Document åˆ—è¡¨\n",
    "    pages = loader.load_and_split() \n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½ PDFï¼Œå…±è®¡ {len(pages)} é¡µã€‚\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. å®æ–½åˆ†å—ç­–ç•¥ (Chunking Strategy)\n",
    "    # ==========================================\n",
    "    # å®ä¾‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨\n",
    "    # chunk_size=200: æ¯å—å°½é‡åŒ…å« 200 ä¸ªå­—ç¬¦\n",
    "    # chunk_overlap=50: ç›¸é‚»å—ä¹‹é—´ä¿ç•™ 50 ä¸ªå­—ç¬¦çš„é‡å å†—ä½™\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200, \n",
    "        chunk_overlap=120\n",
    "    )\n",
    "    \n",
    "    # ä¼ å…¥é¡µé¢åˆ—è¡¨ï¼Œæ‰§è¡Œæ·±å…¥åˆ†å‰²\n",
    "    chunks = text_splitter.split_documents(pages)\n",
    "    \n",
    "    # éªŒè¯åˆ†å—ç»“æœï¼Œä¾‹å¦‚ 3 é¡µçš„ PDF è¢«åˆ‡åˆ†æˆäº†æ•°åä¸ªå°å—\n",
    "    print(f\"ğŸ”ª åˆ†å—å®Œæˆï¼åŸå§‹é¡µé¢è¢«åˆ‡åˆ†æˆäº† {len(chunks)} ä¸ªç‹¬ç«‹çš„ Chunkã€‚\")\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. éªŒè¯é‡å ä¸å…ƒæ•°æ®ä¿ç•™ (ç§‘ç ”é‡ç‚¹è§‚å¯Ÿ)\n",
    "    # ==========================================\n",
    "    if len(chunks) >= 2:\n",
    "        print(\"\\n=== è§‚å¯Ÿ Chunk 0 ===\")\n",
    "        print(f\"å†…å®¹: {chunks[0].page_content}\")\n",
    "        # è§‚å¯Ÿå…ƒæ•°æ®æ˜¯å¦å®Œå¥½ä¼ é€’ï¼ˆç”¨äºåç»­æº¯æºå¼•ç”¨ï¼‰\n",
    "        print(f\"å…ƒæ•°æ®: {chunks[0].metadata}\") \n",
    "        \n",
    "        print(\"\\n=== è§‚å¯Ÿ Chunk 1 ===\")\n",
    "        print(f\"å†…å®¹: {chunks[1].page_content}\")\n",
    "        print(f\"å…ƒæ•°æ®: {chunks[1].metadata}\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ ã€ç§æ•™æç¤ºã€‘å¯¹æ¯” Chunk 0 çš„ç»“å°¾å’Œ Chunk 1 çš„å¼€å¤´ã€‚\")\n",
    "        print(\"ä½ ä¼šå‘ç°æœ‰ä¸€æ®µé‡å¤çš„è¯ (Overlap)ï¼Œè¿™æ­£æ˜¯ä¸ºäº†ä¿è¯æ£€ç´¢æ—¶è¯­ä¹‰ä¸è¢«ç”Ÿç¡¬åˆ‡æ–­ï¼\")\n",
    "\n",
    "        # ==========================================\n",
    "        # 4. Overlap è‡ªæ£€ï¼ˆé‡åŒ–éªŒè¯ï¼Œé¿å…è‚‰çœ¼è¯¯åˆ¤ï¼‰\n",
    "        # ==========================================\n",
    "        def _max_overlap(a: str, b: str, max_len: int = 200) -> int:\n",
    "            \"\"\"è¿”å› a çš„åç¼€ä¸ b çš„å‰ç¼€çš„æœ€å¤§å®Œå…¨é‡å é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰ã€‚\"\"\"\n",
    "            best = 0\n",
    "            limit = min(len(a), len(b), max_len)\n",
    "            for n in range(1, limit + 1):\n",
    "                if a[-n:] == b[:n]:\n",
    "                    best = n\n",
    "            return best\n",
    "\n",
    "        tail = chunks[0].page_content[-120:]\n",
    "        head = chunks[1].page_content[:120]\n",
    "        print(\"\\n=== Overlap è‡ªæ£€ ===\")\n",
    "        print(f\"Chunk 0 å°¾éƒ¨(120 chars): {repr(tail)}\")\n",
    "        print(f\"Chunk 1 å¤´éƒ¨(120 chars): {repr(head)}\")\n",
    "        overlap_len = _max_overlap(chunks[0].page_content, chunks[1].page_content)\n",
    "        print(f\"âœ… æ£€æµ‹åˆ°çš„å®é™… overlap é•¿åº¦: {overlap_len} å­—ç¬¦\")\n",
    "\n",
    "        if overlap_len == 0:\n",
    "            print(\"\\nè¯´æ˜ï¼šä½ è¿™é‡Œçœ‹ä¸åˆ° overlap å¾ˆå¸¸è§ï¼ŒåŸå› é€šå¸¸æ˜¯ PDF æ–‡æœ¬é‡Œæœ‰ç¡¬æ¢è¡Œ(\\\\n)æˆ–æ®µè½åˆ‡åˆ†å¯¼è‡´æœ€å°åˆ‡åˆ†ç‰‡æ®µæœ¬èº«å°± > chunk_overlap(50)ã€‚\")\n",
    "            print(\"RecursiveCharacterTextSplitter çš„ overlap æ˜¯æŒ‰â€˜ç‰‡æ®µâ€™å›é€€ä¿ç•™çš„ï¼Œæ— æ³•ä¿ç•™ç‰‡æ®µçš„ä¸€éƒ¨åˆ†ï¼Œæ‰€ä»¥å¯èƒ½å‡ºç° overlap_len=0ã€‚\")\n",
    "            print(\"å¯é€‰ä¿®å¤ï¼šæŠŠ chunk_overlap è°ƒå¤§ï¼ˆä¾‹å¦‚ 120ï¼‰ï¼Œæˆ–å…ˆå°† page_content ä¸­çš„ \\\\n æ›¿æ¢ä¸ºç©ºæ ¼å†è¿›è¡Œåˆ†å—ã€‚\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"æ‰§è¡Œå¼‚å¸¸ï¼Œè¯·ç¡®ä¿ '{PDF_PATH}' æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„ PDF æ–‡ä»¶ã€‚é”™è¯¯ä¿¡æ¯: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
